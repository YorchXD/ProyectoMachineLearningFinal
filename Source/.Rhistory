)
fviz_pca_ind(res.pca,
label = "none", # hide individual labels, # color by groups
palette = c("#00AFBB", "#E7B800", "#FC4E07"),
addEllipses = TRUE # Concentration ellipses
)
habillage = iris$Species
fviz_pca_ind(res.pca,
label = "none", # hide individual labels
habillage = iris$Species, # color by groups
palette = c("#00AFBB", "#E7B800", "#FC4E07"),
addEllipses = TRUE # Concentration ellipses
)
res.pca <- prcomp(datos_norm2, scale = TRUE)
get_eig(res.pca)
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 50))
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 40))
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 35))
fviz_eig(res.pca)
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 35))
# Extract the results for variables
var <- get_pca_var(res.pca)
var
# Coordinates of variables
head(var$coord)
# Contribution of variables
head(var$contrib)
# Extract the results for variables
var <- get_pca_var(res.pca)
var
# Coordinates of variables
head(var$coord)
# Contribution of variables
head(var$contrib)
# Graph of variables: default plot
fviz_pca_var(res.pca, col.var = "black")
# Control variable colors using their contributions
fviz_pca_var(res.pca, col.var="contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping
)
# Contributions of variables to PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
fviz_pca_ind(res.pca,
col.ind = "cos2", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
# Extract the results for variables
var <- get_pca_var(res.pca)
var
fviz_pca_biplot(res.pca, repel = TRUE,
col.var = "#2E9FDF", # Variables color
col.ind = "#696969"  # Individuals color
)
fviz_pca_ind(res.pca,
col.ind = "cos2", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
# Control variable colors using their contributions
fviz_pca_var(res.pca, col.var="contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping
)
fviz_pca_ind(res.pca,
col.ind = "cos2", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
fviz_pca_ind(res.pca,
col.ind = "cor", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
fviz_pca_ind(res.pca,
col.ind = "coord", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
# Library
library(plotly)
# Library
install.packages(plotly)
# Library
install.packages('plotly')
library(plotly)
install.packages("plotly")
install.packages("plotly")
install.packages("plotly")
install.packages("plotly")
install.packages("plotly")
# A basic boxplot
library(plotly)
# Library
install.packages('plotly')
install.packages("plotly")
# Library
# install.packages('plotly')
library(plotly)
p <- plot_ly(midwest, x = ~percollege, color = ~state, type = "box")
p
p <- plot_ly(datos_norm_prom, color = ~state, type = "box")
p <- plot_ly(datos_norm_prom, x = ~datos_norm_prom, color = ~state, type = "box")
p <- plot_ly(data =datos_norm_prom, color = ~state, type = "box")
p <- plot_ly(data =datos_norm_prom, color = ~state, type = "box")
p <- plot_ly(data =datos_norm_prom,x= ~,color = ~state, type = "box")
p <- plot_ly(data =datos_norm_prom,x= ~datos_norm_prom,color = ~state, type = "box")
p <- plot_ly(data =datos_norm_prom,x= ~X1,color = ~state, type = "box")
p <- plot_ly(data =datos_norm_prom,x= ~X1,color = ~state, type = "box")
p <- plot_ly(data =datos_norm_prom,x= ~X1,color = ~state, type = "box")
p <- plot_ly(datos_norm_prom,x= ~X1,color = ~state, type = "box")
p <- plot_ly(datos_norm2,x= ~X1,color = ~state, type = "box")
p
p <- plot_ly(datos_norm2,color = ~state, type = "box")
p
datos_norm_prom <-as.data.frameapply(datos_norm, 2, mean))
datos_norm_prom <-as.data.frame(apply(datos_norm, 2, mean))
par(mfrow=c(1,2))
plot(datos_norm_prom,type="b",main="Posicion de X v/s Promedios de Columnas X (Normalizadas)", xlab="Posicion X", ylab="Prom. Colunas X.", col="2", pch=18)
boxplot(datos_norm_prom)
p <- plot_ly(datos_norm_prom,color = ~state, type = "box")
p <- plot_ly(datos_norm_prom,color = ~state, type = "box")
p
p <- plot_ly(datos_norm_prom, type = "box")
p
p <- plot_ly(datos_norm_prom, color = c("#00AFBB", "#E7B800", "#FC4E07"), type = "box")
p
p <- plot_ly(datos_norm_prom, type = "box")
p
plot_ly(datos_norm_prom, type = "box")
plot_ly(datos, type = "box")
library(googlesheets)
suppressMessages(library(dplyr))
library(gsheet)
# 4.1 Lectura de los datos
web <-"https://docs.google.com/spreadsheets/d/1cJZIUTPoYliSej8ZQumPdrvWjcZeRyuEqyC4JyXpx-8/edit#gid=1570725307"
#4.2 Agregar el documento descargado a una tabla
datos<-read.csv(text=gsheet2text(web, format='csv'), stringsAsFactors=TRUE, header = TRUE, dec = ".")
#4.3 Muestra la dimensón de la tabla
dim(datos)
#4.4 Verifica para NAs
is.na(datos)
#4.5 Existe algun(os) NAs?
any(is.na(datos))
#4.6 Cuenta los NAs
sum(is.na(datos))
#4.7 omite las filas que contengan NA
datos2<-na.omit(datos)
#4.8 Muestra la dimensón de la tabla
dim(datos2)
#4.9 Muestra que tipo de vectores tiene la tabla
str(datos2)
#4.10 muestra un resumen
View(summary(datos2))
#4.10 muestra un resumen
summary(datos2)
par(mfrow=c(1,2))
#4.11.1 Obtener los minimos de las columnas
minimos<-apply(datos[,-1], 2, min)
par(mfrow=c(1,1))
#4.11.1 Obtener los minimos de las columnas
minimos<-apply(datos[,-1], 2, min)
plot(minimos,type="b",main="Posicion de X v/s Minimos de Columnas X", xlab="Posicion X", ylab="Min. Colunas X.", col="2", pch=18)
#4.11.2 Obtener los promedios de las columnas
promedios<-apply(datos[,-1], 2, mean)
plot(promedios,type="b",main="Posicion de X v/s Promedios de Columnas X", xlab="Posicion X", ylab="Prom. Colunas X.", col="2", pch=18)
#4.11.3 Obtener los maximos de las columnas
maximos<-apply(datos[,-1], 2, max)
plot(maximos,type="b",main="Posicion de X v/s Maximos de Columnas X", xlab="Posicion X", ylab="Max. Colunas X.", col="2", pch=18)
#4.2 Agregar el documento descargado a una tabla
datos<-read.csv(text=gsheet2text(web, format='csv'), stringsAsFactors=FALSE, header = TRUE, dec = ".")
library(googlesheets)
suppressMessages(library(dplyr))
library(gsheet)
# 4.1 Lectura de los datos
web <-"https://docs.google.com/spreadsheets/d/1cJZIUTPoYliSej8ZQumPdrvWjcZeRyuEqyC4JyXpx-8/edit#gid=1570725307"
#4.2 Agregar el documento descargado a una tabla
datos<-read.csv(text=gsheet2text(web, format='csv'), stringsAsFactors=FALSE, header = TRUE, dec = ".")
#4.2 Agregar el documento descargado a una tabla
datos<-read.csv(text=gsheet2text(web, format='csv'), stringsAsFactors=FALSE, header = TRUE, dec = ".")
#4.3 Muestra la dimensón de la tabla
dim(datos)
#4.4 Verifica para NAs
is.na(datos)
#4.5 Existe algun(os) NAs?
any(is.na(datos))
#4.6 Cuenta los NAs
sum(is.na(datos))
#4.7 omite las filas que contengan NA
datos2<-na.omit(datos)
#4.8 Muestra la dimensón de la tabla
dim(datos2)
#4.9 Muestra que tipo de vectores tiene la tabla
str(datos2)
#4.10 muestra un resumen
summary(datos2)
par(mfrow=c(1,1))
#4.11.1 Obtener los minimos de las columnas
minimos<-apply(datos[,-1], 2, min)
plot(minimos,type="b",main="Posicion de X v/s Minimos de Columnas X", xlab="Posicion X", ylab="Min. Colunas X.", col="2", pch=18)
#4.11.2 Obtener los promedios de las columnas
promedios<-apply(datos[,-1], 2, mean)
plot(promedios,type="b",main="Posicion de X v/s Promedios de Columnas X", xlab="Posicion X", ylab="Prom. Colunas X.", col="2", pch=18)
#4.11.3 Obtener los maximos de las columnas
maximos<-apply(datos[,-1], 2, max)
plot(maximos,type="b",main="Posicion de X v/s Maximos de Columnas X", xlab="Posicion X", ylab="Max. Colunas X.", col="2", pch=18)
#5.1Normalizando los datos
normalize <- function(x) { return ((x - min(x)) / (max(x) - min(x)))}
datos_norm <- as.data.frame(lapply(datos[,-1], normalize))
sum(is.na(datos_norm))
dim(datos_norm)
View(datos_norm)
#5.2Verificando que las columnas que tienen NaN, ya que puede ser que toda la columna que se este analizando sea NaN
sum(is.na(datos_norm$X122))
sum(is.na(datos_norm$X127))
sum(is.na(datos_norm$X202))
sum(is.na(datos_norm$X205))
sum(is.na(datos_norm$X206))
sum(is.na(datos_norm$X207))
sum(is.na(datos_norm$X208))
sum(is.na(datos_norm$X209))
sum(is.na(datos_norm$X210))
#5.3 Eliminando las columnas que al ser normalizadas eran NaN
datos_normal1<-datos_norm[,-c(122,127,202,205,206,207,208,209,210)]
View(datos_normal1)
datos_norm_prom <-apply(datos_norm, 2, mean)
par(mfrow=c(1,2))
plot(datos_norm_prom,type="b",main="Posicion de X v/s Promedios de Columnas X (Normalizadas)", xlab="Posicion X", ylab="Prom. Colunas X.", col="2", pch=18)
boxplot(datos_norm_prom)
boxplot(datos_norm_prom,
main = "Salario (dólares hora) según ocupación",
ylab = "Salario",
xlab = "Ocupación",
col = rainbow(6, alpha=0.2),
border = rainbow(6, v=0.6)
)
boxplot(datos_norm_prom,
main = "Promedio de datos Normalizados de X",
ylab = "Promedio de datos Normalizados",
xlab = "X",
col = rainbow(6, alpha=0.2),
border = rainbow(6, v=0.6)
)
par(mfrow=c(1,2))
plot(datos_norm_prom,type="b",main="Posicion de X v/s Promedios de Columnas X (Normalizadas)", xlab="Posicion X", ylab="Prom. Colunas X.", col="2", pch=18)
boxplot(datos_norm_prom,
main = "Promedio de datos Normalizados de X",
ylab = "Promedio de datos Normalizados",
xlab = "Variable X",
col = rainbow(6, alpha=0.2),
border = rainbow(6, v=0.6)
)
#6.1 volviendo a normalizar los datos despues del preprocesamiento de los datos
datos_norm2 <- as.data.frame(lapply(datos_normal1, normalize))
#6.2 Verificando si existen datos nulos despues de normalizar nuevamente
sum(is.na(datos_norm2))
View(datos_norm2)
datos_norm_prom2 <-apply(datos_norm2, 2, mean)
par(mfrow=c(1,2))
plot(datos_norm_prom2,type="b",main="Posicion de X v/s Promedios de Columnas X (Normalizadas)", xlab="Posicion X", ylab="Prom. Colunas X.", col="2", pch=18)
boxplot(datos_norm_prom2,
main = "Promedio de datos Normalizados de X",
ylab = "Promedio de datos Normalizados",
xlab = "Variable X",
col = rainbow(6, alpha=0.2),
border = rainbow(6, v=0.6)
)
#7.1 Visualizacion
#install.packages('factoextra')
library(factoextra)
res.pca <- prcomp(datos_norm2, scale = TRUE)
get_eig(res.pca)
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 35))
# Extract the results for variables
var <- get_pca_var(res.pca)
var
# Control variable colors using their contributions
fviz_pca_var(res.pca, col.var="contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping
)
# Graph of variables: default plot
fviz_pca_var(res.pca, col.var = "black")
fviz_pca_var(res.pca, # Color by the quality of representation)
fviz_pca_var(res.pca, # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
fviz_pca_var(res.pca, # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),repel = TRUE)
fviz_pca_var(res.pca, col.var = "red")
pca3d(res.pca)
library(pca3d)
#7.1 Visualizacion
#install.packages('factoextra')
install.packages('pca3d')
library(pca3d)
pca3d(res.pca)
pca3d(res.pca, gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
metabo
get_eig(res.pca)
#get_eig(res.pca)
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 35))
# Graph of variables: default plot
#fviz_pca_var(res.pca, col.var = "black")
fviz_pca_var(res.pca, col.var = "red")
fviz_pca_ind(res.pca,
col.ind = "cos2", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
data("metabo")
library(pca3d)
data(metabo)
pca <-prcomp(metabo[,-1],scale.=TRUE)
gr  <-factor(metabo[,1])
summary(gr)
View(metabo)
pca3d(res.pca, group = c(1:42))
res.pca <- prcomp(datos_norm2, scale = TRUE)
pca3d(res.pca, group = c(1:42))
pca3d(res.pca, group = c(1:42))
pca2d(pca,group=c(1:42),legend="topleft")
pca2d(res.pca,group=c(1:42),legend="topleft")
par(mfrow=c(1,1))
pca2d(res.pca,group=c(1:42),legend="topleft")
dim(datos_norm2)
pca2d(res.pca,group=c(1:43),legend="topleft")
pca2d(res.pca,group=c(0:42),legend="topleft")
pca2d(res.pca,group=c(1:42),legend="topleft")
par(mfrow=c(1,2))
#get_eig(res.pca)
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 35))
fviz_pca_var(res.pca, col.var = "red")
par(mfrow=c(1,2))
fviz_pca_ind(res.pca,
col.ind = "cos2", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
pca2d(res.pca,group=c(1:42),legend="topleft")
fviz_pca_ind(res.pca,
col.ind = "cos2", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
pca2d(res.pca,group=c(1:42),legend="topleft")
par(mfrow=c(1,1))
pca2d(res.pca,group=c(1:42),legend="topleft")
pca2d(res.pca,group=c(1:42),legend="topright")
pca2d(res.pca,group=c(1:42))
fviz_pca_biplot(res.pca, label ="var", col.ind="cos2") +
theme_minimal()
fviz_pca_ind(res.pca,
col.ind = "cos2", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
pca2d(res.pca,group=c(1:42))
par(mfrow=c(1,2))
fviz_pca_ind(res.pca,
col.ind = "cos2", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
pca2d(res.pca,group=c(1:42))
fviz_pca_ind(res.pca,
col.ind = "cos2", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
pca2d(res.pca,group=c(1:42))
par(mfrow=c(1,1))
fviz_pca_ind(res.pca,
col.ind = "cos2", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
pca2d(res.pca,group=c(1:42))
#get_eig(res.pca)
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 35))
fviz_pca_var(res.pca, col.var = "red")
fviz_pca_ind(res.pca,
col.ind = "cos2", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
pca2d(res.pca,group=c(1:42))
pca3d(res.pca, group = c(1:42))
Boruta(Clas ~.,data=datos_norm2,doTrace=2)
Boruta(Class ~.,data=datos_norm2,doTrace=2)
library(googlesheets)
suppressMessages(library(dplyr))
library(gsheet)
# 4.1 Lectura de los datos
web <-"https://docs.google.com/spreadsheets/d/1cJZIUTPoYliSej8ZQumPdrvWjcZeRyuEqyC4JyXpx-8/edit#gid=1570725307"
#4.2 Agregar el documento descargado a una tabla
datos<-read.csv(text=gsheet2text(web, format='csv'), stringsAsFactors=FALSE, header = TRUE, dec = ".")
#4.3 Muestra la dimensón de la tabla
dim(datos)
#4.11.1 Obtener los minimos de las columnas
minimos<-apply(datos[,-1], 2, min)
plot(minimos,type="b",main="Posicion de X v/s Minimos de Columnas X", xlab="Posicion X", ylab="Min. Colunas X.", col="2", pch=18)
#4.11.2 Obtener los promedios de las columnas
promedios<-apply(datos[,-1], 2, mean)
plot(promedios,type="b",main="Posicion de X v/s Promedios de Columnas X", xlab="Posicion X", ylab="Prom. Colunas X.", col="2", pch=18)
#4.11.3 Obtener los maximos de las columnas
maximos<-apply(datos[,-1], 2, max)
plot(maximos,type="b",main="Posicion de X v/s Maximos de Columnas X", xlab="Posicion X", ylab="Max. Colunas X.", col="2", pch=18)
datos_norm <- as.data.frame(lapply(datos, normalize))
#5.1Normalizando los datos
normalize <- function(x) { return ((x - min(x)) / (max(x) - min(x)))}
datos_norm <- as.data.frame(lapply(datos, normalize))
sum(is.na(datos_norm))
dim(datos_norm)
View(datos_norm)
sum(is.na(datos_norm))
#5.2Verificando que las columnas que tienen NaN, ya que puede ser que toda la columna que se este analizando sea NaN
sum(is.na(datos_norm$X122))
sum(is.na(datos_norm$X127))
sum(is.na(datos_norm$X202))
sum(is.na(datos_norm$X205))
sum(is.na(datos_norm$X206))
sum(is.na(datos_norm$X207))
sum(is.na(datos_norm$X208))
sum(is.na(datos_norm$X209))
sum(is.na(datos_norm$X210))
#5.3 Eliminando las columnas que al ser normalizadas eran NaN que corresponden a los x(122,127,202,205,206,207,208,209,210)
datos_normal1<-datos_norm[,-c(123,128,203,206,207,208,209,210,211)]
View(datos_normal1)
datos_norm_prom <-apply(datos_norm[,-1], 2, mean)
#Obtengo los promedios solo de las columnas X
datos_norm_prom <-apply(datos_norm[,-1], 2, mean)
par(mfrow=c(1,2))
plot(datos_norm_prom,type="b",main="Posicion de X v/s Promedios de Columnas X (Normalizadas)", xlab="Posicion X", ylab="Prom. Colunas X.", col="2", pch=18)
boxplot(datos_norm_prom,
main = "Promedio de datos Normalizados de X",
ylab = "Promedio de datos Normalizados",
xlab = "Variable X",
col = rainbow(6, alpha=0.2),
border = rainbow(6, v=0.6)
)
#6.1 volviendo a normalizar los datos despues del preprocesamiento de los datos
datos_norm2 <- as.data.frame(lapply(datos_normal1, normalize))
#6.2 Verificando si existen datos nulos despues de normalizar nuevamente
sum(is.na(datos_norm2))
View(datos_norm2)
#Obtengo los promedios solo de las columnas X para ver como vuelven a quedar los datos al normalizar nuevamente
datos_norm_prom2 <-apply(datos_norm2[,-1], 2, mean)
par(mfrow=c(1,2))
plot(datos_norm_prom2,type="b",main="Posicion de X v/s Promedios de Columnas X (Normalizadas)", xlab="Posicion X", ylab="Prom. Colunas X.", col="2", pch=18)
boxplot(datos_norm_prom2,
main = "Promedio de datos Normalizados de X",
ylab = "Promedio de datos Normalizados",
xlab = "Variable X",
col = rainbow(6, alpha=0.2),
border = rainbow(6, v=0.6)
)
#7.1 Visualizacion
#install.packages('factoextra')
#install.packages('pca3d')
library(factoextra)
library(pca3d)
par(mfrow=c(1,1))
res.pca <- prcomp(datos_norm2, scale = TRUE)
dim(datos_norm2)
#get_eig(res.pca)
fviz_screeplot(res.pca, addlabels = TRUE, ylim = c(0, 35))
fviz_pca_ind(res.pca,
col.ind = "cos2", # Color by the quality of representation
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE     # Avoid text overlapping
)
pca2d(res.pca,group=c(1:42))
pca3d(res.pca, group = c(1:42))
str(datos_norm2)
boruta<-Boruta(datos_norm$Y,data=datos_norm2,doTrace=2)
#8.1 Reducción de la Dimensionalidad
#install.packages('Boruta')
library(Boruta)
#8.1 Reducción de la Dimensionalidad
install.packages('Boruta')
install.packages("Boruta")
#8.1 Reducción de la Dimensionalidad
#install.packages('Boruta')
library(Boruta)
#8.1 Reducción de la Dimensionalidad
install.packages('Boruta')
install.packages("Boruta")
library(Boruta)
boruta<-Boruta(datos_norm$Y,data=datos_norm2,doTrace=2)
boruta<-Boruta(Y~.,data=datos_norm2,doTrace=2)
print(boruta)
plot(boruta)
boruta<-Boruta(Y~.,data=datos_norm2,doTrace=2, maxRuns=500)
print(boruta)
plot(boruta)
plot(boruta, las=2)
plot(boruta, las=2)
plot(boruta)
#plot(boruta, las=2)
plotImpHistory(boruta)
TentativeRoughFix(boruta, averageOver = Inf)
#plot(boruta, las=2)
plotImpHistory(boruta)
TentativeRoughFix(boruta, averageOver = Inf)
library(googlesheets)
suppressMessages(library(dplyr))
library(gsheet)
library(googlesheets)
suppressMessages(library(dplyr))
